{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_tutorial_4_build_model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMrk7+IkoXLLQ9GBPuJ4AHx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/makkimaki/pytorch_official_tutorial/blob/main/pytorch_tutorial_4_build_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cikE6P0TbfrF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urKHNvMbarM6"
      },
      "source": [
        "import os \n",
        "import torch \n",
        "from torch import nn \n",
        "from torch.utils.data import DataLoader \n",
        "from torchvision import datasets, transforms "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNLgHyaqbhf0"
      },
      "source": [
        "## Get device for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqKw_485bYz4",
        "outputId": "a69aa987-abdb-4815-8d4a-a837a087fc2f"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D77z0XCbsY_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4i824XVfA-9"
      },
      "source": [
        "# Define the Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRZct8PKfETU"
      },
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear_relu_stack(x)\n",
        "        return x \n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iipmB42sfnTT",
        "outputId": "70d1535e-5268-45ed-cdc6-30d87bc3e571"
      },
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0G_wJfXgMld"
      },
      "source": [
        "ここでインスタンス化した`model`にデータを渡せば勝手に`forward`メソッドまでが実行される．`model.forward()`とはしないように！"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxG-TrnjftGo",
        "outputId": "dbd0e676-e10a-4637-dd47-a073f77b2438"
      },
      "source": [
        "X = torch.rand(1, 28, 28, device=device)\n",
        "logits = model(X)\n",
        "pred_prob = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_prob.argmax(1)\n",
        "\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted class: tensor([0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEXMwTOvgpGN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAcrkNg6gwwW"
      },
      "source": [
        "各層で何が起きているかを見ていこう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByW_p-wdgzyh",
        "outputId": "9bdfded9-ebfc-423b-e8d3-8c85e2f39095"
      },
      "source": [
        "input_image = torch.rand(3,28,28)\n",
        "print(input_image.size())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9Y6FZIog5mv"
      },
      "source": [
        "## nn.Flatten\n",
        "2D 28*28の画像を隣接する784ピクセルの値に変換する．\n",
        "（この時，ミニバッチ次元(dim=0)は保存されたまま）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuQSKWacg12o",
        "outputId": "74563c69-d00a-45eb-98e4-e5249214ff83"
      },
      "source": [
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(input_image)\n",
        "\n",
        "print(flat_image.shape)\n",
        "\n",
        "print(flat_image.size)\n",
        "print(flat_image.size())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 784])\n",
            "<built-in method size of Tensor object at 0x7f7fc5d4a460>\n",
            "torch.Size([3, 784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_zwiyzzhjdO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3TN9fNUhse9"
      },
      "source": [
        "## nn.Linear\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtPFrGjPhvp9",
        "outputId": "386f2b8e-541a-48df-a3d9-c8f71c7a4172"
      },
      "source": [
        "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(hidden1.size())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox_LZ6sshw_3"
      },
      "source": [
        "## nn.ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz-Ka_0ZhwG_",
        "outputId": "c309da7b-b647-44e0-9ac3-6ae63e678811"
      },
      "source": [
        "print(f\"Before ReLU \\n: {hidden1}\\n\\n\")\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"After ReLU \\n: {hidden1}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before ReLU \n",
            ": tensor([[0.0000, 0.3708, 0.3230, 0.2592, 0.2365, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.2311, 0.1798, 0.4547, 0.0000, 0.4527, 0.0000, 0.0044, 0.3616,\n",
            "         0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.5207, 0.5377, 0.3597, 0.0265, 0.2986, 0.0038, 0.0000,\n",
            "         0.0000, 0.6516, 0.1145, 0.7049, 0.0000, 0.0892, 0.0000, 0.3658, 0.2842,\n",
            "         0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.1479, 0.2185, 0.0423, 0.0000, 0.1138, 0.0399, 0.0000,\n",
            "         0.0000, 0.1341, 0.1158, 0.4120, 0.0000, 0.3418, 0.1692, 0.0780, 0.3004,\n",
            "         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n",
            "\n",
            "\n",
            "After ReLU \n",
            ": tensor([[0.0000, 0.3708, 0.3230, 0.2592, 0.2365, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.2311, 0.1798, 0.4547, 0.0000, 0.4527, 0.0000, 0.0044, 0.3616,\n",
            "         0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.5207, 0.5377, 0.3597, 0.0265, 0.2986, 0.0038, 0.0000,\n",
            "         0.0000, 0.6516, 0.1145, 0.7049, 0.0000, 0.0892, 0.0000, 0.3658, 0.2842,\n",
            "         0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.1479, 0.2185, 0.0423, 0.0000, 0.1138, 0.0399, 0.0000,\n",
            "         0.0000, 0.1341, 0.1158, 0.4120, 0.0000, 0.3418, 0.1692, 0.0780, 0.3004,\n",
            "         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AROr69ruiG84"
      },
      "source": [
        "## nn.Sequential"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2d9BDUph4Bv"
      },
      "source": [
        "seq_modules = nn.Sequential(\n",
        "    flatten, \n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10)\n",
        ")\n",
        "input_image = torch.rand(3, 28, 28)\n",
        "logits = seq_modules(input_image)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgZaRAfoiZJ4"
      },
      "source": [
        "## nn.Softmax\n",
        "`dim`パラメータは，確率の和が１になるように沿う次元の総数を表す．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wxn72wyTiVDP"
      },
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "pred_prob = softmax(logits)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGXv_L1Y4B-7"
      },
      "source": [
        "## Model parameters\n",
        "`nn.Module`を継承したサブクラスモデルは，中のオブジェクトを全てトラッキングできるようになる．\n",
        "\n",
        "`parameters()`および`named_parameters()`メソッドを使う．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcnbQL60ixD_",
        "outputId": "dd626bee-6fdd-4e9d-dba8-46ca375998f1"
      },
      "source": [
        "print(\"Model structure: \", model, \"\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer; {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model structure:  NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            ") \n",
            "\n",
            "\n",
            "Layer; linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0147,  0.0278, -0.0274,  ..., -0.0222,  0.0350,  0.0247],\n",
            "        [ 0.0071,  0.0086,  0.0109,  ...,  0.0210, -0.0322, -0.0003]],\n",
            "       grad_fn=<SliceBackward>) \n",
            "\n",
            "Layer; linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0171, -0.0255], grad_fn=<SliceBackward>) \n",
            "\n",
            "Layer; linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0015, -0.0141,  0.0159,  ...,  0.0164, -0.0048,  0.0219],\n",
            "        [-0.0216,  0.0276, -0.0365,  ..., -0.0323, -0.0306, -0.0205]],\n",
            "       grad_fn=<SliceBackward>) \n",
            "\n",
            "Layer; linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([0.0387, 0.0055], grad_fn=<SliceBackward>) \n",
            "\n",
            "Layer; linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0335, -0.0098,  0.0388,  ..., -0.0171, -0.0064, -0.0053],\n",
            "        [-0.0392,  0.0177,  0.0172,  ..., -0.0257,  0.0174,  0.0293]],\n",
            "       grad_fn=<SliceBackward>) \n",
            "\n",
            "Layer; linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([ 0.0249, -0.0413], grad_fn=<SliceBackward>) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk-EOV085QDw",
        "outputId": "60db705e-82cc-428d-82bc-b95f965d69b2"
      },
      "source": [
        "for param in model.parameters():\n",
        "    print(param)\n",
        "    print(param.size())\n",
        "    print(\"-\"*50)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0147,  0.0278, -0.0274,  ..., -0.0222,  0.0350,  0.0247],\n",
            "        [ 0.0071,  0.0086,  0.0109,  ...,  0.0210, -0.0322, -0.0003],\n",
            "        [-0.0014, -0.0231, -0.0173,  ...,  0.0207,  0.0352,  0.0132],\n",
            "        ...,\n",
            "        [ 0.0322, -0.0253, -0.0302,  ..., -0.0219, -0.0012, -0.0289],\n",
            "        [-0.0334, -0.0273,  0.0108,  ..., -0.0163,  0.0216,  0.0197],\n",
            "        [ 0.0055, -0.0272, -0.0043,  ..., -0.0308, -0.0094, -0.0144]],\n",
            "       requires_grad=True)\n",
            "torch.Size([512, 784])\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([ 1.7076e-02, -2.5483e-02,  1.5028e-02, -2.8640e-02,  5.9781e-03,\n",
            "        -6.7036e-03,  1.2181e-02, -1.2551e-02, -1.9929e-02,  3.4838e-02,\n",
            "        -1.0371e-02,  9.6974e-03, -3.2585e-02, -8.9118e-03,  2.4155e-03,\n",
            "         3.3955e-02,  5.9348e-03, -2.5974e-02, -3.1512e-02,  8.8929e-03,\n",
            "        -3.5425e-04,  1.5985e-02, -6.0709e-03, -7.0757e-04,  2.8023e-02,\n",
            "        -1.0124e-02,  6.6626e-03, -2.3270e-02,  1.7447e-02,  1.0720e-02,\n",
            "         3.4597e-02, -3.1583e-02, -1.7550e-02,  1.4090e-02,  1.1703e-02,\n",
            "         9.9592e-03,  2.6507e-02, -2.1910e-02,  9.8778e-05,  1.3476e-02,\n",
            "        -1.5754e-02,  1.6592e-02,  1.1563e-02,  7.5265e-03,  1.3937e-02,\n",
            "         3.0782e-02,  3.3496e-02,  1.7020e-02,  3.3057e-02, -2.8089e-02,\n",
            "         9.9405e-03, -1.6213e-04, -2.8517e-02, -1.6640e-02, -2.3716e-02,\n",
            "         2.5158e-02,  1.3405e-02,  1.7760e-02, -2.1259e-02,  1.3204e-02,\n",
            "        -3.0068e-02, -1.0205e-02, -2.2089e-02, -2.4093e-02,  2.0507e-02,\n",
            "         1.7132e-02,  7.0116e-03,  2.8239e-02,  2.7415e-02, -6.1313e-03,\n",
            "         2.7264e-02, -1.6909e-02, -1.2099e-02, -2.8134e-02, -2.1296e-02,\n",
            "         6.7465e-03,  2.2679e-02,  2.8925e-02, -2.2223e-02,  3.6832e-03,\n",
            "        -1.8631e-02, -3.1396e-02, -3.3857e-02,  4.6898e-03, -1.9019e-02,\n",
            "        -1.4047e-02, -6.8870e-03,  7.2972e-03,  4.2082e-03, -1.1971e-02,\n",
            "         4.0205e-03, -3.2621e-02,  1.5626e-02,  2.0940e-02,  3.5571e-02,\n",
            "        -3.3254e-03,  2.9244e-02,  2.0370e-02, -1.3092e-02,  3.2473e-02,\n",
            "        -3.1924e-02, -2.1902e-03, -1.0716e-02, -3.4293e-03,  1.6775e-02,\n",
            "         2.9794e-02,  2.4551e-02, -3.1336e-02,  3.0058e-02, -2.1860e-02,\n",
            "        -3.5187e-02,  1.6585e-02, -2.2832e-02, -3.2899e-03,  1.6367e-02,\n",
            "        -2.8881e-02,  1.2102e-02,  1.0566e-02,  1.3582e-02,  1.7368e-03,\n",
            "         1.5276e-02, -1.2547e-02,  1.8451e-02,  2.4996e-02,  1.8534e-03,\n",
            "        -1.5178e-02,  2.6994e-02, -5.7402e-03, -2.2488e-02, -3.2048e-02,\n",
            "         2.3131e-02,  5.6229e-03, -4.4810e-03, -2.1005e-03,  4.1210e-03,\n",
            "         2.8888e-02,  1.2388e-02,  3.1605e-02,  8.6322e-03,  2.9632e-02,\n",
            "        -7.9026e-03,  1.3216e-02,  3.0628e-02,  1.5399e-02,  8.3755e-03,\n",
            "        -2.6629e-02,  1.6541e-02,  2.6727e-02,  1.0536e-03,  3.4175e-02,\n",
            "        -2.2553e-02, -2.6115e-02,  1.9829e-02, -2.5282e-02,  2.7844e-02,\n",
            "         3.4468e-02,  6.1972e-03,  6.1912e-03, -6.5020e-03, -1.6058e-02,\n",
            "        -3.1480e-02,  3.5254e-02, -2.0860e-02,  6.5569e-03,  2.7767e-02,\n",
            "        -2.6403e-02, -3.1232e-02,  3.5608e-03,  1.1935e-02, -3.4595e-02,\n",
            "         7.1863e-03, -1.1137e-02,  3.0663e-02, -1.0843e-04,  1.4432e-02,\n",
            "        -2.3547e-02,  1.0460e-02,  2.5926e-02,  9.4280e-03, -2.8946e-02,\n",
            "        -2.3493e-02,  5.6229e-03, -2.0852e-02, -1.6190e-03,  6.4765e-03,\n",
            "         1.7877e-02,  3.2653e-02, -3.4675e-02, -1.0251e-02, -9.4931e-03,\n",
            "        -3.0320e-02, -2.0182e-02,  7.1923e-03,  3.4122e-02,  5.5579e-04,\n",
            "         8.4657e-03, -1.7670e-02, -1.4625e-02,  3.3897e-02,  3.2063e-02,\n",
            "        -2.8892e-02,  2.6821e-02, -1.9182e-02,  8.4650e-04,  2.0849e-02,\n",
            "         1.6963e-02,  1.3118e-02,  3.1980e-02,  2.2536e-02,  8.2729e-03,\n",
            "        -2.2212e-03,  8.2552e-03,  2.3724e-02,  1.8673e-02, -1.3116e-02,\n",
            "        -1.6609e-02, -2.9702e-02, -2.7586e-02, -1.6672e-03, -1.5361e-02,\n",
            "         3.4497e-02,  1.2422e-02,  6.9724e-03, -6.6036e-03,  9.8369e-03,\n",
            "        -3.0025e-02,  3.4178e-02, -1.1149e-02,  8.7115e-03,  3.0022e-02,\n",
            "        -1.7651e-02,  3.1777e-02, -1.2298e-02,  2.9574e-02,  1.4832e-02,\n",
            "         2.4362e-03,  5.8752e-03,  1.3623e-02, -3.5298e-03,  1.0050e-02,\n",
            "        -3.0096e-02,  2.8729e-02, -1.2829e-02,  2.5863e-02, -8.1079e-03,\n",
            "        -3.3855e-02,  1.8908e-02, -2.2428e-02,  2.9500e-02, -2.3755e-02,\n",
            "        -2.7781e-02, -6.0865e-03,  2.9949e-02,  9.2512e-03, -5.2931e-03,\n",
            "         3.4033e-02,  3.5004e-03,  3.5049e-02, -2.8568e-02, -3.4543e-02,\n",
            "        -2.0314e-02,  2.3578e-02,  2.1480e-02, -3.4305e-02,  7.9151e-03,\n",
            "         5.8005e-03, -2.8520e-02, -2.1685e-02, -2.8097e-02,  3.3238e-02,\n",
            "         2.8301e-02, -7.4220e-03, -2.7089e-03,  2.5683e-03, -6.9851e-03,\n",
            "         1.3499e-02, -3.1417e-02, -1.7496e-02,  3.3580e-02, -1.0712e-02,\n",
            "        -1.3058e-02,  1.2549e-02,  1.2174e-02, -1.9991e-02, -1.5576e-02,\n",
            "        -4.8600e-03, -1.1097e-02, -2.3830e-02,  2.8079e-02, -1.7903e-03,\n",
            "        -1.5580e-02, -5.3916e-03,  1.2733e-02,  1.6031e-02,  1.5667e-02,\n",
            "        -2.5943e-03,  3.1323e-02, -3.4249e-02,  1.6224e-02, -2.1104e-03,\n",
            "        -2.4736e-02, -1.5395e-02, -8.2339e-04,  2.1159e-02,  2.4757e-02,\n",
            "        -3.1476e-03, -1.0946e-02, -2.7632e-02, -1.5257e-02,  3.3891e-02,\n",
            "         3.1142e-02, -3.4682e-02,  3.1218e-02, -2.7235e-02, -5.5659e-03,\n",
            "         2.8163e-02,  8.3856e-03, -1.6627e-02,  2.7842e-02,  3.0453e-02,\n",
            "         2.7047e-02, -3.5249e-02,  5.0183e-03,  2.6305e-02,  2.8396e-02,\n",
            "        -2.6382e-02, -1.4743e-02, -1.0432e-02,  1.8223e-02, -3.9459e-03,\n",
            "        -3.4502e-02, -2.7793e-03, -2.7257e-02,  4.8847e-03, -2.1880e-02,\n",
            "        -2.4837e-02,  9.4584e-03, -1.0908e-02,  2.8646e-02, -1.6433e-02,\n",
            "         7.3916e-03,  6.4767e-03,  4.4700e-03,  3.0419e-03,  2.7943e-02,\n",
            "        -9.4543e-03, -1.9566e-02, -1.9921e-02,  3.2324e-02,  3.3844e-02,\n",
            "        -2.1252e-02,  3.4601e-02,  3.2040e-02,  2.8762e-02,  1.3302e-02,\n",
            "         1.0480e-02,  1.2148e-02, -8.4701e-03,  3.4575e-02, -2.0224e-03,\n",
            "        -1.6313e-02,  2.9015e-02,  5.1311e-03,  2.0404e-02, -2.2520e-02,\n",
            "        -8.5615e-03, -3.2757e-02,  1.7257e-02, -2.7385e-03, -1.6174e-03,\n",
            "        -2.6398e-02, -3.3276e-02, -3.5589e-02,  2.9446e-02,  2.8252e-02,\n",
            "         2.6532e-02,  3.0157e-02, -1.5343e-02,  1.6750e-02,  8.3489e-03,\n",
            "         1.8966e-02,  2.6163e-02, -3.0232e-02, -3.2460e-02, -3.8847e-03,\n",
            "         5.3412e-03,  1.5058e-02,  1.5062e-02, -2.7287e-02, -1.6520e-02,\n",
            "         2.0295e-02, -1.1797e-02, -2.1526e-02,  3.0207e-02, -2.9689e-02,\n",
            "        -6.2704e-03,  1.7975e-02, -1.0846e-02,  3.5663e-02, -9.8261e-03,\n",
            "        -3.1875e-02,  1.4857e-02,  2.2114e-02,  8.7227e-03, -2.8487e-02,\n",
            "        -2.9408e-02,  1.6991e-02, -2.8848e-02,  1.1878e-02,  4.5375e-03,\n",
            "         1.8534e-02, -2.7560e-02,  4.3003e-03, -4.8042e-03,  1.6451e-02,\n",
            "        -3.4366e-02,  2.8678e-02, -1.0606e-02,  5.1537e-03,  1.4690e-03,\n",
            "         3.3502e-02, -2.7735e-02, -2.0258e-02, -1.5961e-02, -1.3380e-02,\n",
            "         2.4197e-02,  3.4747e-02,  2.3749e-02,  1.8306e-02, -2.4218e-02,\n",
            "        -1.0985e-03, -8.2665e-03, -2.5848e-02,  2.1887e-02,  3.2990e-02,\n",
            "         1.7589e-02,  2.0883e-02,  3.0754e-02,  3.9211e-03,  6.4340e-03,\n",
            "         1.9077e-02, -1.0419e-02, -2.7543e-02,  1.6898e-02, -2.1076e-02,\n",
            "        -2.3801e-03,  1.9228e-04, -2.2041e-02, -2.5432e-02, -1.2857e-02,\n",
            "        -1.9263e-02,  1.6922e-02, -3.4766e-02, -3.5587e-02,  3.5231e-02,\n",
            "        -2.2423e-02,  8.2706e-05, -1.8633e-02, -4.1331e-04, -1.2106e-02,\n",
            "        -9.4615e-03, -1.8230e-02,  1.6920e-02,  1.4854e-02,  2.2706e-02,\n",
            "         2.5706e-02, -1.1024e-02, -4.8035e-03, -4.4138e-03, -6.8889e-03,\n",
            "        -4.6113e-03,  2.7820e-02,  2.1351e-02,  8.3921e-03,  1.4350e-02,\n",
            "        -1.7877e-02, -3.6342e-03, -2.9211e-02,  1.1714e-03,  1.7563e-02,\n",
            "        -1.2439e-02, -3.3083e-02, -3.5676e-02,  7.9879e-03,  1.9018e-02,\n",
            "         1.5948e-02, -2.7724e-02, -2.7220e-02, -2.0142e-02,  8.5951e-03,\n",
            "        -1.3522e-02, -1.3598e-02,  9.8854e-03,  1.2972e-02,  1.7425e-02,\n",
            "         9.0447e-03, -1.0237e-02,  1.5294e-02, -6.8206e-03,  9.3925e-03,\n",
            "        -1.5066e-04,  8.0595e-03,  1.6572e-02,  2.5540e-02, -1.0083e-02,\n",
            "        -2.0511e-02,  3.3374e-02,  1.8192e-02, -2.6559e-02,  1.9596e-02,\n",
            "         2.4860e-02, -1.0367e-02], requires_grad=True)\n",
            "torch.Size([512])\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[ 0.0015, -0.0141,  0.0159,  ...,  0.0164, -0.0048,  0.0219],\n",
            "        [-0.0216,  0.0276, -0.0365,  ..., -0.0323, -0.0306, -0.0205],\n",
            "        [-0.0070,  0.0314, -0.0336,  ..., -0.0314, -0.0342, -0.0016],\n",
            "        ...,\n",
            "        [-0.0352, -0.0394,  0.0440,  ...,  0.0300,  0.0333, -0.0334],\n",
            "        [ 0.0385, -0.0345, -0.0251,  ...,  0.0131,  0.0150, -0.0275],\n",
            "        [-0.0082,  0.0023, -0.0310,  ...,  0.0116,  0.0339, -0.0251]],\n",
            "       requires_grad=True)\n",
            "torch.Size([512, 512])\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([ 3.8680e-02,  5.4768e-03,  2.1086e-02,  1.5063e-03, -2.6493e-02,\n",
            "        -2.7640e-02, -3.5677e-02, -2.5082e-03, -3.1666e-02, -3.7390e-02,\n",
            "        -2.7235e-02, -4.8356e-04,  1.4194e-02, -8.4848e-03, -3.1595e-02,\n",
            "        -5.3481e-03,  2.4229e-02,  1.3450e-02, -3.2963e-02,  1.6253e-02,\n",
            "        -3.3014e-02,  1.8127e-03,  3.1966e-02,  1.3168e-02,  1.8871e-02,\n",
            "        -1.9289e-02, -4.1779e-02, -1.4729e-02,  1.6234e-02,  2.4494e-02,\n",
            "         3.2210e-02,  3.7856e-02,  1.6156e-03,  8.4566e-03, -8.0760e-03,\n",
            "        -9.7099e-03,  4.4177e-02,  7.4427e-03,  1.1060e-02,  2.1560e-03,\n",
            "         2.9132e-02,  1.2676e-02,  4.1405e-02, -3.0755e-02,  3.7289e-02,\n",
            "         4.3481e-02, -3.5919e-02,  4.3508e-02,  2.2043e-02,  8.7564e-03,\n",
            "         3.1605e-02,  3.7680e-02,  1.0129e-02,  1.2629e-02, -9.4915e-03,\n",
            "         2.4596e-02, -1.4834e-02,  2.2809e-02, -2.4570e-02,  3.8847e-02,\n",
            "        -1.3922e-02, -3.8435e-03,  9.5386e-03,  1.1420e-02,  2.4932e-02,\n",
            "        -2.2778e-02, -4.0167e-02, -2.9527e-02,  4.1219e-02,  2.7458e-02,\n",
            "        -2.2361e-02, -6.5150e-03, -4.0626e-02,  3.4238e-03, -1.9919e-02,\n",
            "        -2.1056e-02, -2.9575e-02,  9.4496e-03,  3.2671e-02, -1.7038e-02,\n",
            "         5.7423e-04, -4.3313e-02,  4.2281e-02,  6.6254e-03,  1.6304e-02,\n",
            "         1.5531e-03, -1.7803e-02, -2.1229e-02,  4.2099e-02,  3.8842e-02,\n",
            "        -3.3140e-02, -8.2548e-03, -3.5911e-02,  4.0438e-02,  4.1550e-02,\n",
            "        -3.1126e-02,  6.4632e-03, -3.1628e-02, -1.8799e-02,  2.5261e-02,\n",
            "        -4.1102e-02,  9.9230e-03, -6.8189e-03,  2.0321e-02,  2.8173e-02,\n",
            "        -9.8993e-03, -2.1733e-02, -8.4017e-03, -3.2063e-03,  1.7890e-02,\n",
            "         3.7744e-02, -4.0340e-02,  3.0309e-02, -4.0405e-02,  3.0312e-02,\n",
            "        -3.6276e-02,  4.2578e-02,  2.6387e-02,  6.0088e-03,  2.2589e-02,\n",
            "        -1.3069e-02, -3.6832e-02, -1.3092e-03, -3.9448e-02,  4.3298e-02,\n",
            "         3.3058e-02,  4.0484e-02, -3.9117e-02,  1.1863e-02,  2.4550e-03,\n",
            "         1.3727e-03, -1.3053e-02,  1.1917e-03, -2.6681e-02, -1.1418e-02,\n",
            "         2.1420e-02,  2.9643e-02,  3.3665e-02, -3.3019e-02, -2.0825e-02,\n",
            "         2.6039e-02, -5.8054e-04,  3.9745e-02, -4.2737e-02, -7.3502e-03,\n",
            "         9.5765e-03,  6.6252e-03,  2.5498e-02, -4.5215e-03, -4.1674e-02,\n",
            "         6.8086e-03,  2.8517e-02,  1.1470e-02,  3.4272e-02,  7.6731e-03,\n",
            "         2.6010e-02, -3.3485e-02, -1.9326e-02, -2.9027e-02, -1.3981e-02,\n",
            "        -2.7990e-02, -4.3007e-02, -1.1677e-02, -9.8997e-03, -3.1938e-02,\n",
            "        -4.0537e-02, -1.0398e-02,  1.4102e-02, -3.4442e-02,  1.3555e-02,\n",
            "         2.9579e-02, -2.1372e-02,  4.2711e-02, -5.8912e-03, -1.6112e-02,\n",
            "        -3.1920e-02,  7.2417e-03,  2.5328e-02, -2.5840e-03, -1.3547e-02,\n",
            "         3.3303e-02, -4.1240e-02,  3.3323e-02,  1.2279e-02, -1.1005e-02,\n",
            "         5.3641e-03,  3.6171e-04, -1.3652e-02,  1.7185e-03,  7.7774e-03,\n",
            "        -3.2163e-02,  2.5192e-02, -3.7784e-02,  2.5936e-02, -1.5076e-02,\n",
            "         4.8466e-03,  1.2594e-02,  2.3360e-02,  2.5971e-02, -4.0642e-02,\n",
            "         4.1526e-02,  8.8432e-03, -3.9383e-02, -1.6497e-02, -2.7035e-02,\n",
            "         3.1666e-02,  1.1502e-02,  1.7238e-02,  5.5230e-03, -4.2152e-02,\n",
            "         1.2440e-02, -3.8839e-02, -3.8468e-02,  2.3024e-02, -2.6877e-02,\n",
            "        -2.1878e-02, -6.0120e-03,  1.2160e-02, -3.6571e-02,  1.5537e-02,\n",
            "        -8.9515e-03, -5.1215e-03,  1.9429e-03, -1.1887e-02, -1.8943e-02,\n",
            "         1.6621e-02, -1.0201e-03, -4.8118e-03,  1.7643e-02, -2.9957e-02,\n",
            "         1.8480e-02,  2.8849e-02, -4.4147e-02, -2.3438e-02, -2.0782e-02,\n",
            "        -1.1833e-02,  2.4549e-02,  2.6165e-02, -2.8608e-02,  1.5966e-02,\n",
            "        -3.2259e-02,  3.0124e-03, -2.0636e-02, -3.3294e-02, -2.4694e-02,\n",
            "         4.2670e-02, -1.0322e-02, -2.0680e-02, -3.5415e-02,  3.0361e-02,\n",
            "         2.0398e-03, -3.2303e-02,  1.1621e-03, -3.8629e-03, -1.0508e-02,\n",
            "         3.6270e-02, -4.1184e-02, -3.1346e-02, -3.9181e-02, -2.5060e-02,\n",
            "         2.0090e-02,  2.4869e-02,  2.0297e-02,  3.8685e-02, -2.8082e-03,\n",
            "         2.6403e-02, -3.1911e-02,  1.8842e-02, -2.3861e-02,  3.0340e-02,\n",
            "         8.0137e-03, -1.3915e-02, -9.8294e-03, -2.2417e-02,  6.7601e-03,\n",
            "         3.2146e-02, -3.0193e-02, -3.9032e-02,  4.3668e-02, -1.4157e-02,\n",
            "         2.3144e-02,  1.3350e-02, -2.0138e-02, -2.7385e-03,  2.8886e-02,\n",
            "        -2.3145e-02, -2.7041e-02, -5.3789e-03, -3.2201e-04, -1.7063e-02,\n",
            "         2.4121e-02, -3.4837e-02, -3.9001e-02, -1.1575e-02,  1.7454e-02,\n",
            "         8.4483e-03,  1.2872e-02,  6.9673e-03, -9.6270e-03,  9.4360e-03,\n",
            "         1.4085e-02,  4.2455e-02,  2.1900e-03,  2.4670e-04,  7.0716e-03,\n",
            "        -1.2393e-02,  4.2762e-02,  4.9345e-03,  2.6747e-02, -4.2888e-02,\n",
            "         3.6439e-02,  2.2333e-02,  3.7527e-02,  3.8864e-02, -9.3525e-03,\n",
            "         3.9294e-02,  2.8323e-02, -4.1333e-02, -3.8320e-02, -1.5050e-02,\n",
            "        -4.2471e-03,  1.7007e-03,  2.3040e-02,  1.9575e-02,  2.4495e-02,\n",
            "         4.3626e-02,  1.0156e-02, -3.8992e-02,  2.0419e-02,  3.0984e-02,\n",
            "        -2.3836e-02,  1.2171e-02,  3.2686e-02,  2.1299e-02, -3.4063e-02,\n",
            "         4.5354e-03, -2.1124e-02, -4.1568e-02,  1.2473e-02, -3.0870e-02,\n",
            "        -2.4907e-02,  3.3312e-02, -2.6069e-02, -2.4891e-02,  3.9412e-02,\n",
            "        -1.1996e-02, -4.4059e-02,  7.4935e-03, -1.2280e-02,  4.0126e-02,\n",
            "         2.3335e-02, -9.9555e-03, -2.4493e-02,  2.5203e-02,  1.4355e-02,\n",
            "         3.1008e-02,  3.8955e-02, -3.8762e-02,  3.6330e-02, -2.4069e-02,\n",
            "         1.4973e-03,  2.6102e-02,  3.1090e-02,  3.0742e-02,  1.3770e-03,\n",
            "         1.3778e-02,  4.6109e-03, -3.6540e-02,  4.4166e-02, -2.0477e-02,\n",
            "        -6.3327e-03, -5.2834e-04,  9.8548e-03,  2.8942e-02, -8.5094e-05,\n",
            "        -2.1398e-02, -3.1795e-02, -1.5455e-02, -4.0284e-02, -5.6560e-03,\n",
            "         1.4125e-02,  6.8230e-03,  3.7010e-03, -3.8808e-02, -9.8450e-03,\n",
            "        -3.2629e-02, -4.5751e-03, -1.5847e-02,  8.1927e-03,  3.3815e-02,\n",
            "        -3.2592e-03, -2.1122e-02, -1.3984e-02,  3.4545e-02,  1.6165e-02,\n",
            "        -3.3214e-02, -3.6494e-03, -1.7509e-02,  4.9612e-04,  2.5397e-02,\n",
            "         5.5386e-03, -2.6576e-02,  2.3767e-02,  1.5524e-02, -3.8991e-02,\n",
            "         4.3211e-02,  1.7643e-02,  4.5093e-03, -2.4905e-03,  2.4570e-02,\n",
            "         4.5481e-03, -1.1959e-02,  1.6987e-02, -2.9655e-02,  2.2712e-02,\n",
            "        -1.8680e-02,  6.8930e-03,  1.2523e-02,  3.5706e-02, -3.7007e-02,\n",
            "         4.2180e-02,  2.7779e-02, -4.1197e-02,  1.2802e-02,  3.3954e-02,\n",
            "        -1.4386e-02,  3.9671e-02,  2.1892e-02, -3.1471e-02, -2.5245e-02,\n",
            "        -1.4950e-02, -2.9149e-03,  2.3191e-02,  4.3412e-02, -4.3996e-02,\n",
            "         2.6632e-02,  1.1362e-02, -2.3414e-02, -2.5163e-02, -2.4465e-02,\n",
            "        -3.0118e-02,  2.8883e-02,  2.3051e-02, -2.5485e-04, -2.2248e-02,\n",
            "        -3.9681e-02, -2.0240e-02,  4.3149e-02, -3.6670e-02,  3.5476e-02,\n",
            "        -2.5176e-02,  2.9722e-02,  3.0354e-02, -3.6736e-02, -1.8771e-02,\n",
            "         4.2121e-02,  2.1389e-02,  3.2392e-02, -3.2145e-02, -1.2053e-02,\n",
            "         7.4952e-04, -3.9109e-02,  4.0277e-02,  2.5862e-02,  3.3915e-02,\n",
            "        -5.9089e-03,  2.3585e-02,  3.1750e-02, -1.4626e-02,  7.0009e-03,\n",
            "         2.6469e-02, -1.7172e-02,  3.9846e-02,  1.6986e-04,  3.7779e-03,\n",
            "        -1.6923e-02,  4.3167e-02,  2.1420e-03,  9.9573e-03, -1.6812e-02,\n",
            "         3.8159e-02, -1.6106e-02, -2.6403e-02,  3.1903e-02, -7.0305e-03,\n",
            "        -7.2623e-03,  4.4134e-02, -4.2575e-02,  3.5271e-02, -4.8867e-03,\n",
            "         4.3242e-02, -3.5085e-02, -2.8871e-02,  3.2383e-02, -6.2754e-04,\n",
            "         4.2173e-02,  1.6718e-02, -1.9315e-02, -2.0007e-02, -2.5383e-02,\n",
            "        -7.9084e-03, -7.9652e-04,  1.3146e-02, -1.1156e-02, -2.6777e-02,\n",
            "         3.5890e-02,  2.4011e-03,  1.6623e-02, -1.5395e-03, -3.1058e-02,\n",
            "        -3.5401e-02, -1.3859e-02], requires_grad=True)\n",
            "torch.Size([512])\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[ 0.0335, -0.0098,  0.0388,  ..., -0.0171, -0.0064, -0.0053],\n",
            "        [-0.0392,  0.0177,  0.0172,  ..., -0.0257,  0.0174,  0.0293],\n",
            "        [-0.0010,  0.0059,  0.0174,  ..., -0.0140, -0.0292, -0.0433],\n",
            "        ...,\n",
            "        [ 0.0068, -0.0329, -0.0407,  ...,  0.0329, -0.0125, -0.0125],\n",
            "        [ 0.0080, -0.0342, -0.0167,  ..., -0.0355,  0.0211,  0.0400],\n",
            "        [-0.0434, -0.0169, -0.0130,  ...,  0.0064, -0.0028,  0.0208]],\n",
            "       requires_grad=True)\n",
            "torch.Size([10, 512])\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([ 0.0249, -0.0413,  0.0299,  0.0227,  0.0351, -0.0109, -0.0151,  0.0170,\n",
            "        -0.0151,  0.0209], requires_grad=True)\n",
            "torch.Size([10])\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1XVEFws6T9g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}